import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors

questions = []
answers = []

with open("data.txt", "r", encoding="utf8") as f:
    for line in f:
        line = line.strip()

        # B·ªè qua d√≤ng tr·ªëng
        if not line:
            print("‚ö† B·ªè qua d√≤ng tr·ªëng")
            continue

        # Ki·ªÉm tra c√≥ d·∫•u ph√¢n t√°ch hay kh√¥ng
        if "|||" not in line:
            print("‚ö† D√≤ng sai ƒë·ªãnh d·∫°ng, kh√¥ng c√≥ '|||':", line)
            continue

        parts = line.split("|||")

        # D√≤ng ph·∫£i c√≥ ƒë√∫ng 2 ph·∫ßn (c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi)
        if len(parts) != 2:
            print("‚ö† D√≤ng sai ƒë·ªãnh d·∫°ng (th·ª´a ho·∫∑c thi·∫øu '|||'):", line)
            continue

        q, a = parts
        q = q.strip()
        a = a.strip()

        if q == "" or a == "":
            print("‚ö† B·ªè qua d√≤ng thi·∫øu n·ªôi dung:", line)
            continue

        questions.append(q)
        answers.append(a)

# ƒê·∫£m b·∫£o c√≥ d·ªØ li·ªáu h·ª£p l·ªá
if len(questions) == 0:
    raise ValueError("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá trong data.txt")

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(questions)

model = NearestNeighbors(n_neighbors=1, metric="cosine")
model.fit(X)

pickle.dump((vectorizer, model, answers), open("model.pkl", "wb"))

print("‚úÖ Hu·∫•n luy·ªán xong! ƒê√£ l∆∞u model.pkl")
print(f"üìå T·ªïng s·ªë c√¢u h·ªèi h·ª£p l·ªá: {len(questions)}")
